# --- 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸° ---
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from sentence_transformers import SentenceTransformer
import uvicorn
import torch
from typing import List, Dict, Any
import numpy as np
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import cosine_similarity
import lancedb
import os
import subprocess
import tempfile
import re
from urllib.parse import urlparse, parse_qs
import webvtt
from io import StringIO
import time
import threading

# --- 2. ì„¤ì • ë° ëª¨ë¸/DB ë¡œë“œ ---
MODEL_NAME = 'all-MiniLM-L6-v2'
app = FastAPI(title="Local Vector AI Server", version="4.0.0")

# --- LanceDB ì„¤ì • ---
db_path = "./lancedb" # í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— lancedb í´ë” ìƒì„±
db = lancedb.connect(db_path)
table = None # í…Œì´ë¸” ê°ì²´ë¥¼ ì €ì¥í•  ì „ì—­ ë³€ìˆ˜

# ì„œë²„ ì‹œì‘ ì‹œ ì‹¤í–‰ë˜ëŠ” ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
@app.on_event("startup")
async def startup_event():
    global model, table
    
    # ëª¨ë¸ ë¡œë“œ
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"INFO: ì‚¬ìš©í•˜ëŠ” ì¥ì¹˜: {device}")
    try:
        print(f"INFO: '{MODEL_NAME}' ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘...")
        model = SentenceTransformer(MODEL_NAME, device=device)
        print("INFO: ëª¨ë¸ ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"ERROR: ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        model = None

    # LanceDB í…Œì´ë¸” ì—´ê¸° ë˜ëŠ” ìƒì„±
    table_name = "memories"
    try:
        # 1. ì¼ë‹¨ í…Œì´ë¸”ì„ ì—´ë ¤ê³  ì‹œë„í•©ë‹ˆë‹¤.
        table = db.open_table(table_name)
        print(f"INFO: LanceDB í…Œì´ë¸” '{table_name}'ì„ ì„±ê³µì ìœ¼ë¡œ ì—´ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        # 2. ì–´ë–¤ ì¢…ë¥˜ì˜ ì˜¤ë¥˜ë“  ë°œìƒí•˜ë©´ (ì¦‰, í…Œì´ë¸”ì´ ì—†ìœ¼ë©´), ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        print(f"INFO: LanceDB í…Œì´ë¸” '{table_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤. (ì˜¤ë¥˜: {e})")
        if model:
            try:
                # í…Œì´ë¸”ì„ ìƒì„±í•˜ê¸° ìœ„í•œ ì´ˆê¸° ë°ì´í„° (ìŠ¤í‚¤ë§ˆ ì •ì˜ìš©)
                initial_vector = model.encode("init").tolist()
                schema_data = [{"vector": initial_vector, "id": 0, "text": "initial_record"}]
                
                # ê¸°ì¡´ì— ê°™ì€ ì´ë¦„ì˜ í…Œì´ë¸”ì´ ë‚¨ì•„ìˆì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´, ë®ì–´ì“°ê¸° ëª¨ë“œ(overwrite)ë¡œ ì•ˆì „í•˜ê²Œ ìƒì„±
                table = db.create_table(table_name, data=schema_data, mode="overwrite")
                print(f"INFO: LanceDB í…Œì´ë¸” '{table_name}' ìƒì„±ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
            except Exception as create_e:
                print(f"ERROR: LanceDB í…Œì´ë¸” ìƒì„± ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {create_e}")
        else:
            print("ERROR: ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ë¡œ LanceDB í…Œì´ë¸”ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


# --- 3. API ë°ì´í„° í˜•ì‹ ì •ì˜ ---
class EmbeddingRequest(BaseModel):
    text: str
class EmbeddingResponse(BaseModel):
    embedding: List[float]

class AddMemoryRequest(BaseModel):
    id: int
    text: str
class AddMemoryResponse(BaseModel):
    message: str

class SearchMemoryRequest(BaseModel):
    text: str
    limit: int = 5
class SearchMemoryResponse(BaseModel):
    results: List[str]

class ClusteringRequest(BaseModel):
    vectors: List[List[float]]
    num_clusters: int = 5
class ClusteringResponse(BaseModel):
    labels: List[int]

class YouTubeTranscriptRequest(BaseModel):
    url: str

class YouTubeTranscriptResponse(BaseModel):
    transcript: str

# â–¼â–¼â–¼ [ê°œì„ ] ëª…ì‹œì ì¸ ì‘ë‹µ ëª¨ë¸ì„ ì •ì˜í•©ë‹ˆë‹¤. (ChatGPT ì œì•ˆ 3) â–¼â–¼â–¼
class TranscriptSegment(BaseModel):
    start: float
    end: float
    text: str

class TranscriptResponse(BaseModel):
    video_id: str
    segments: List[TranscriptSegment]

class YouTubeTranscriptRequest(BaseModel):
    url: str

class SearchSegmentsRequest(BaseModel):
    query: str
    segments: List[Dict[str, Any]]

class SearchResultItem(BaseModel):
    index: int
    text: str
    start: float
    score: float

class SearchSegmentsResponse(BaseModel):
    results: List[SearchResultItem]

class MediaDownloadRequest(BaseModel):
    url: str
    format: str = "mp4"
    output_path: str

class MediaDownloadResponse(BaseModel):
    message: str
    file_path: str

# --- 4. API ì—”ë“œí¬ì¸íŠ¸ ìƒì„± ---
@app.post("/add", response_model=AddMemoryResponse)
async def add_memory(request: AddMemoryRequest):
    if model is None or table is None: raise HTTPException(status_code=503, detail="ì„œë²„ ì¤€ë¹„ ì•ˆë¨")
    try:
        vector = model.encode(request.text).tolist()
        table.add([{"vector": vector, "id": request.id, "text": request.text}])
        return {"message": f"ê¸°ì–µ ID {request.id}ê°€ ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤."}
    except Exception as e:
        print(f"ERROR: ê¸°ì–µ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/search", response_model=SearchMemoryResponse)
async def search_memory(request: SearchMemoryRequest):
    if model is None or table is None: raise HTTPException(status_code=503, detail="ì„œë²„ ì¤€ë¹„ ì•ˆë¨")
    try:
        query_vector = model.encode(request.text)
        results = table.search(query_vector).limit(request.limit).to_df()
        # ê²°ê³¼ DataFrameì—ì„œ 'text' ì»¬ëŸ¼ë§Œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
        return {"results": results['text'].tolist()}
    except Exception as e:
        print(f"ERROR: ê¸°ì–µ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/get_all_vectors")
async def get_all_vectors():
    if table is None: raise HTTPException(status_code=503, detail="ì„œë²„ ì¤€ë¹„ ì•ˆë¨")
    try:
        # LanceDBì˜ ëª¨ë“  ë°ì´í„°ë¥¼ ê°€ì¥ ê¸°ë³¸ì ì¸ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
        all_records = table.search().to_list()
        
        # ê° ë”•ì…”ë„ˆë¦¬ì—ì„œ 'vector' ê°’ë§Œ ì¶”ì¶œí•˜ì—¬ ìƒˆë¡œìš´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“­ë‹ˆë‹¤.
        vectors_list = [record['vector'] for record in all_records]
        
        return {"vectors": vectors_list}
    except Exception as e:
        print(f"ERROR: ëª¨ë“  ë²¡í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# --- 4. API ì—”ë“œí¬ì¸íŠ¸ ìƒì„± ---
@app.post("/embedding", response_model=EmbeddingResponse)
async def create_embedding(request: EmbeddingRequest):
    if model is None: raise HTTPException(status_code=503, detail="ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
    if not request.text or not request.text.strip(): raise HTTPException(status_code=400, detail="í…ìŠ¤íŠ¸ í•„ìš”")
    try:
        embedding = model.encode(request.text, convert_to_tensor=False).tolist()
        return {"embedding": embedding}
    except Exception as e: raise HTTPException(status_code=500, detail=str(e))

# âœ¨ ì˜ë¯¸ í´ëŸ¬ìŠ¤í„°ë§ì„ ìœ„í•œ ìƒˆë¡œìš´ API ì—”ë“œí¬ì¸íŠ¸
@app.post("/cluster", response_model=ClusteringResponse)
async def run_clustering(request: ClusteringRequest):
    """
    ì…ë ¥ëœ ë²¡í„°ë“¤ì„ K-Means ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ì§€ì •ëœ ê°œìˆ˜ì˜ ê·¸ë£¹ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    """
    if len(request.vectors) < request.num_clusters:
        raise HTTPException(status_code=400, detail="ë°ì´í„°(ë²¡í„°)ì˜ ê°œìˆ˜ëŠ” í´ëŸ¬ìŠ¤í„°ì˜ ê°œìˆ˜ë³´ë‹¤ ë§ê±°ë‚˜ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤.")
    
    try:
        # K-Means í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰
        kmeans = KMeans(n_clusters=request.num_clusters, random_state=0, n_init='auto')
        kmeans.fit(np.array(request.vectors))
        
        # ê° ë°ì´í„°ê°€ ì†í•œ ê·¸ë£¹ ë¼ë²¨ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
        return {"labels": kmeans.labels_.tolist()}
    except Exception as e:
        print(f"ERROR: í´ëŸ¬ìŠ¤í„°ë§ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"í´ëŸ¬ìŠ¤í„°ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.get("/")
def read_root():
    return {"status": "Local Embedding & Clustering Server is running", "model": MODEL_NAME if model else "Not loaded"}

# // ìœ íŠœë¸Œ ìë§‰ ì¶”ì¶œì„ ìœ„í•œ API ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
@app.post("/youtube-transcript", response_model=TranscriptResponse)
def get_youtube_transcript(request: YouTubeTranscriptRequest):
    raw_url = request.url
    
    # 1. URL ì •ê·œí™”
    try:
        parsed_url = urlparse(raw_url)
        video_id = None
        if 'youtube.com' in parsed_url.netloc:
            query_params = parse_qs(parsed_url.query)
            if 'v' in query_params: video_id = query_params['v'][0]
            elif parsed_url.path.startswith('/shorts/'): video_id = parsed_url.path.split('/shorts/')[1]
        elif 'youtu.be' in parsed_url.netloc:
            video_id = parsed_url.path.lstrip('/')
        if not video_id: raise ValueError("URLì—ì„œ ë¹„ë””ì˜¤ IDë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        clean_url = f"https://www.youtube.com/watch?v={video_id}"
        print(f"INFO: (URL ì •ê·œí™”) ì›ë³¸: {raw_url} -> ì •ì œ: {clean_url}")
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"ìœ íš¨í•˜ì§€ ì•Šì€ URLì…ë‹ˆë‹¤: {str(e)}")
    video_url = clean_url
    
    # 2. ì„ì‹œ ë””ë ‰í† ë¦¬ì—ì„œ ìë§‰ ì¶”ì¶œ
    with tempfile.TemporaryDirectory() as temp_dir:
        vtt_file_path = None
        try:
            print("INFO: (yt-dlp) ì•ˆì •í™” ëª¨ë“œë¡œ ìë§‰ ì¶”ì¶œì„ ì‹œë„í•©ë‹ˆë‹¤.")
            
            # â–¼â–¼â–¼ [í•µì‹¬ ê°œì„ ] ì¿¨ë‹¤ìš´ ì˜µì…˜ì„ ì¶”ê°€í•˜ê³ , í”Œëœ A/Bë¥¼ í†µí•©í•©ë‹ˆë‹¤. â–¼â–¼â–¼
            command = [
                'yt-dlp',
                '--restrict-filenames', # íŒŒì¼ëª…ì— í¬í•¨ë  ìˆ˜ ì—†ëŠ” íŠ¹ìˆ˜ë¬¸ì, ì´ëª¨ì§€ ë“±ì„ ì•ˆì „í•œ ë¬¸ìë¡œ ì¹˜í™˜
                '--write-sub', '--write-automatic-sub',
                '--sub-lang', 'ko,en',
                '--skip-download',
                '--sub-format', 'vtt',
                '--output', os.path.join(temp_dir, '%(id)s.%(ext)s'),
                '--sleep-interval', '2',
                '--max-sleep-interval', '5',
                video_url
            ]
            
            result = subprocess.run(command, capture_output=True, text=True, encoding='utf-8')

            # â–¼â–¼â–¼ [ìµœì¢… ê°œì„ ] ìƒì„¸ ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€ â–¼â–¼â–¼
            if result.returncode != 0:
                print(f"ERROR: (yt-dlp) ì‹¤í–‰ ì‹¤íŒ¨. STDERR ì „ì²´:\n{result.stderr}")
                raise subprocess.CalledProcessError(result.returncode, command, output=result.stdout, stderr=result.stderr)

            downloaded_files = os.listdir(temp_dir)
            print(f"DEBUG: (yt-dlp) ì„ì‹œ í´ë” ë‚´ìš©: {downloaded_files}") # ìƒì„±ëœ íŒŒì¼ ëª©ë¡ í™•ì¸

            # â–¼â–¼â–¼ [í•µì‹¬ ê°œì„ ] "í•˜ë‚˜ë¼ë„ ì„±ê³µí•˜ë©´ OK" ë¡œì§ â–¼â–¼â–¼
            downloaded_files = os.listdir(temp_dir)
            found_subs = [f for f in downloaded_files if f.endswith('.vtt')]
            
            if not found_subs:
                # ì–´ë–¤ ìë§‰ íŒŒì¼ë„ ìƒì„±ë˜ì§€ ì•Šì•˜ë‹¤ë©´, ê·¸ë•Œê°€ ì§„ì§œ ì‹¤íŒ¨ì…ë‹ˆë‹¤.
                raise FileNotFoundError("yt-dlpê°€ ì–´ë–¤ ìë§‰ íŒŒì¼ë„ ìƒì„±í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # í•œêµ­ì–´ ìë§‰(.ko.vtt)ì´ ìˆìœ¼ë©´ ìµœìš°ì„ ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤.
            korean_subs = [f for f in found_subs if '.ko.vtt' in f]
            if korean_subs:
                vtt_file_path = os.path.join(temp_dir, korean_subs[0])
                print(f"INFO: (yt-dlp) í•œêµ­ì–´ ìë§‰ '{korean_subs[0]}'ì„ ì„ íƒí–ˆìŠµë‹ˆë‹¤.")
            else:
                # í•œêµ­ì–´ ìë§‰ì´ ì—†ìœ¼ë©´, ì°¾ì€ ê²ƒ ì¤‘ ì•„ë¬´ê±°ë‚˜ ì²« ë²ˆì§¸ ê²ƒì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
                vtt_file_path = os.path.join(temp_dir, found_subs[0])
                print(f"WARN: (yt-dlp) í•œêµ­ì–´ ìë§‰ì„ ì°¾ì„ ìˆ˜ ì—†ì–´, ì‚¬ìš© ê°€ëŠ¥í•œ ìë§‰ '{found_subs[0]}'ì„ ëŒ€ì‹  ì‚¬ìš©í•©ë‹ˆë‹¤.")

        except (subprocess.CalledProcessError, FileNotFoundError) as e:
            error_message = e.stderr if hasattr(e, 'stderr') else str(e)
            raise HTTPException(status_code=404, detail=f"ì´ ì˜ìƒì˜ ìë§‰ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {error_message}")
        
        # 3. VTT íŒŒì¼ íŒŒì‹±
        try:
            with open(vtt_file_path, 'r', encoding='utf-8') as f: vtt_content = f.read()
            vtt_content = re.sub(r'(WEBVTT\s*?\n)+', 'WEBVTT\n', vtt_content.strip())
            try:
                captions = webvtt.read_buffer(StringIO(vtt_content))
            except Exception: # ë” ë„“ì€ ë²”ìœ„ì˜ íŒŒì‹± ì—ëŸ¬ë¥¼ ì¡ìŠµë‹ˆë‹¤.
                print("WARN: (VTT íŒŒì‹±) ê¸°ë³¸ íŒŒì‹± ì‹¤íŒ¨, UTF-8-SIG ì¸ì½”ë”©ìœ¼ë¡œ ì¬ì‹œë„.")
                captions = webvtt.read_buffer(StringIO(vtt_content.encode('utf-8-sig').decode('utf-8')))
            segments = []
            for caption in captions:
                # `&gt;&gt;` ê°™ì€ HTML ì—”í‹°í‹°ë¥¼ ì‹¤ì œ ë¬¸ìë¡œ ë³€í™˜í•˜ê³ , ë¶ˆí•„ìš”í•œ ê³µë°±ì„ ì •ë¦¬í•©ë‹ˆë‹¤.
                clean_text = caption.text.replace('&gt;&gt;', '').strip().replace('\n', ' ')
                if clean_text: # í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì¶”ê°€
                    segments.append({ "start": caption.start_in_seconds, "end": caption.end_in_seconds, "text": clean_text })
            print(f"INFO: (yt-dlp) ìë§‰ íŒŒì‹± ì„±ê³µ! {len(segments)}ê°œì˜ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
            return { "video_id": video_id, "segments": segments }
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"ì¶”ì¶œëœ ìë§‰ íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜: {str(e)}")

# ê°•ì œ ë™ê¸°í™”ë¥¼ ìœ„í•œ 'ë°ì´í„°ë² ì´ìŠ¤ ì¬ê±´ì¶•' API
@app.post("/rebuild_db")
async def rebuild_db(request: dict):
    global table
    try:
        # server.jsë¡œë¶€í„° ë°›ì€ ëª¨ë“  ê¸°ì–µ ë°ì´í„° (ì˜ˆ: [{'id': 1, 'text': '...'}, ...])
        memories_to_add = request.get('data', [])
        if not memories_to_add:
            raise ValueError("ì¬êµ¬ì¶•í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # 1. ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ (ì˜¤ë¥˜ê°€ ë‚˜ë„ ë¬´ì‹œ)
        db.drop_table("memories", ignore_missing=True)
        print("INFO: (Rebuild) ê¸°ì¡´ 'memories' í…Œì´ë¸”ì„ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
        
        # 2. ëª¨ë“  ê¸°ì–µ í…ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ë²¡í„°ë¡œ ë³€í™˜ (GPUë¥¼ í™œìš©í•˜ì—¬ ë§¤ìš° ë¹ ë¦„)
        print(f"INFO: (Rebuild) {len(memories_to_add)}ê°œì˜ ê¸°ì–µì„ ì„ë² ë”©í•˜ëŠ” ì¤‘...")
        texts_to_embed = [item['text'] for item in memories_to_add]
        vectors = model.encode(texts_to_embed).tolist()
        
        # 3. LanceDBì— ì €ì¥í•  ìµœì¢… ë°ì´í„° í˜•ì‹ìœ¼ë¡œ ì¬ì¡°ë¦½
        data_for_lancedb = [
            {"vector": vec, "id": mem['id'], "text": mem['text']}
            for mem, vec in zip(memories_to_add, vectors)
        ]

        # 4. ìƒˆ í…Œì´ë¸” ìƒì„±
        table = db.create_table("memories", data=data_for_lancedb, mode="overwrite")
        print(f"INFO: (Rebuild) {len(data_for_lancedb)}ê°œì˜ ë°ì´í„°ë¡œ 'memories' í…Œì´ë¸”ì„ ìƒˆë¡œ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
        
        return {"message": "VectorDB ì¬êµ¬ì¶• ì„±ê³µ"}
    except Exception as e:
        print(f"ERROR: VectorDB ì¬êµ¬ì¶• ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/search-segments", response_model=SearchSegmentsResponse)
async def search_segments_fastapi(request: SearchSegmentsRequest):
    if model is None:
        raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    try:
        query = request.query
        segments_data = request.segments

        if not query or not segments_data:
            raise HTTPException(status_code=400, detail="Query and segments data are required")

        query_vector = model.encode([query])
        segment_vectors = np.array([seg['vector'] for seg in segments_data])

        similarities = cosine_similarity(query_vector, segment_vectors)[0]

        # ìœ ì‚¬ë„ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬ëœ ì¸ë±ìŠ¤ (ìƒìœ„ 5ê°œ)
        top_indices = np.argsort(similarities)[::-1][:5]
        
        results = [{
            "index": int(i),
            "text": segments_data[i]["text"],
            "start": segments_data[i]["start"],
            "score": float(similarities[i])
        } for i in top_indices if similarities[i] >= 0.3] # ê´€ë ¨ ì—†ëŠ” ê²°ê³¼ í•„í„°ë§

        return {"results": results}

    except Exception as e:
        print(f"ERROR: ì„¸ê·¸ë¨¼íŠ¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/rebuild_db")
async def rebuild_db(request: dict):
    """
    Node.js ì„œë²„ë¡œë¶€í„° ë°›ì€ ëª¨ë“  ê¸°ì–µ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ VectorDBë¥¼ ì™„ì „íˆ ì¬êµ¬ì¶•í•©ë‹ˆë‹¤.
    """
    global table
    if model is None:
        raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    try:
        memories_to_add = request.get('data', [])
        if not memories_to_add:
            raise HTTPException(status_code=400, detail="ì¬êµ¬ì¶•í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        db_path = "./lancedb"
        db_conn = lancedb.connect(db_path)
        
        table_name = "memories"
        db_conn.drop_table(table_name, ignore_missing=True)
        print(f"INFO: (Rebuild) ê¸°ì¡´ '{table_name}' í…Œì´ë¸”ì„ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
        
        print(f"INFO: (Rebuild) {len(memories_to_add)}ê°œì˜ ê¸°ì–µì„ ì„ë² ë”©í•˜ëŠ” ì¤‘...")
        texts_to_embed = [item['text'] for item in memories_to_add]
        vectors = model.encode(texts_to_embed).tolist()
        
        data_for_lancedb = [
            {"vector": vec, "id": mem['id'], "text": mem['text']}
            for mem, vec in zip(memories_to_add, vectors)
        ]

        table = db_conn.create_table(table_name, data=data_for_lancedb, mode="overwrite")
        print(f"INFO: (Rebuild) {len(data_for_lancedb)}ê°œì˜ ë°ì´í„°ë¡œ '{table_name}' í…Œì´ë¸”ì„ ìƒˆë¡œ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
        
        return {"message": f"VectorDB ì¬êµ¬ì¶• ì„±ê³µ. {len(data_for_lancedb)}ê°œì˜ ê¸°ì–µ ì²˜ë¦¬ë¨."}
    except Exception as e:
        print(f"ERROR: VectorDB ì¬êµ¬ì¶• ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    
# ë§ŒëŠ¥ ë¯¸ë””ì–´ ë‹¤ìš´ë¡œë” 

class MediaDownloadRequest(BaseModel):
    url: str
    format: str = "mp4"  # 'mp4' ë˜ëŠ” 'mp3'
    output_path: str = "downloads" # ë‹¤ìš´ë¡œë“œ ê²½ë¡œ (ê¸°ë³¸ê°’: 'downloads')

class MediaDownloadResponse(BaseModel):
    message: str
    file_path: str

@app.post("/download-media", response_model=MediaDownloadResponse)
def download_media(request: MediaDownloadRequest):
    video_url = request.url.strip()
    output_format = request.format.lower()
    output_path = request.output_path

    print(f"INFO: (yt-dlp) ë‹¤ìš´ë¡œë“œ ìš”ì²­ ìˆ˜ì‹  â€” URL: {video_url}, í¬ë§·: {output_format}")
    os.makedirs(output_path, exist_ok=True)

    output_template = os.path.join(output_path, "%(id)s.%(ext)s")

    command = [
        "yt-dlp",
        "--restrict-filenames",
        "--no-overwrites",
        "--prefer-ffmpeg",
        "-o", output_template,
    ]

    if output_format == "mp3":
        command.extend([
            "-x",
            "--audio-format", "mp3",
            "--audio-quality", "0",
            "--prefer-ffmpeg",
            # â–¼â–¼â–¼ [í•µì‹¬ ìˆ˜ì •] "ffmpeg:" ì ‘ë‘ì‚¬ë¥¼ ì œê±°í•˜ì—¬ ì˜¬ë°”ë¥¸ ë¬¸ë²•ìœ¼ë¡œ ìˆ˜ì •í•©ë‹ˆë‹¤. â–¼â–¼â–¼
            "--postprocessor-args", "-af loudnorm,aresample=44100,aformat=channel_layouts=stereo"
        ])
    else:
        command.extend([
            "-f", "bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best",
            "--merge-output-format", "mp4"
        ])

    command.append(video_url)

    try:
        print(f"INFO: (yt-dlp) ì‹¤í–‰ ëª…ë ¹ì–´: {' '.join(command)}")
        # âœ… stderrë„ í¬í•¨í•´ì„œ ëª¨ë‘ UTF-8ë¡œ ì‹œë„, ì‹¤íŒ¨ ì‹œ CP949ë¡œ fallback
        try:
            result = subprocess.run(
                command, check=True, capture_output=True, text=True, encoding="utf-8"
            )
            combined_output = (result.stdout or "") + (result.stderr or "")
        except UnicodeDecodeError:
            result = subprocess.run(
                command, check=True, capture_output=True, text=True, encoding="cp949"
            )
            combined_output = (result.stdout or "") + (result.stderr or "")

        # âœ… stdout+stderr ì „ì²´ë¥¼ ë¼ì¸ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
        output_lines = combined_output.splitlines()
        file_path = None

        for line in output_lines:
            if any(key in line for key in ["Destination:", "Downloading", "Merging formats into"]):
                match = re.search(r'([A-Za-z]:[\\/].*?\.(mp4|mp3|m4a|webm))', line)
                if match:
                    file_path = match.group(1)
                    break

        if not file_path:
            # ë§ˆì§€ë§‰ ìˆ˜ë‹¨ìœ¼ë¡œ ë””ë ‰í„°ë¦¬ ì§ì ‘ ìŠ¤ìº”
            possible = [
                os.path.join(output_path, f)
                for f in os.listdir(output_path)
                if f.endswith(f".{output_format}")
            ]
            if possible:
                file_path = max(possible, key=os.path.getctime)
            else:
                raise FileNotFoundError("ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì˜ ìµœì¢… ê²½ë¡œë¥¼ ë¡œê·¸ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        file_path = os.path.abspath(file_path)
        print(f"âœ… (yt-dlp) ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {file_path}")

        return {
            "message": f"{output_format.upper()} ë‹¤ìš´ë¡œë“œ ì„±ê³µ",
            "file_path": file_path.replace("\\", "/"),
        }

    except subprocess.CalledProcessError as e:
        raise HTTPException(status_code=500, detail=f"yt-dlp ì˜¤ë¥˜: {e.stderr}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜: {str(e)}")

# ==========================================================
# ğŸ¯ ì˜¤ë˜ëœ ë‹¤ìš´ë¡œë“œ íŒŒì¼ ìë™ ì •ë¦¬ ìŠ¤ì¼€ì¤„ëŸ¬
# ==========================================================

def cleanup_downloads(path="public/downloads", max_age_hours=24):
    """
    ì§€ì •ëœ í´ë” ë‚´ì—ì„œ ì˜¤ë˜ëœ ë¯¸ë””ì–´ íŒŒì¼(mp3/mp4/webm/m4a)ì„ ìë™ìœ¼ë¡œ ì‚­ì œí•©ë‹ˆë‹¤.
    DB, ë¡œê·¸, ê¸°ì–µ ë°ì´í„°ëŠ” ì ˆëŒ€ ê±´ë“œë¦¬ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """
    now = time.time()
    deleted_files = 0

    # í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ê·¸ëƒ¥ íŒ¨ìŠ¤
    if not os.path.exists(path):
        return

    for f in os.listdir(path):
        fp = os.path.join(path, f)
        # íŒŒì¼ë§Œ ëŒ€ìƒìœ¼ë¡œ
        if os.path.isfile(fp):
            age = (now - os.path.getmtime(fp)) / 3600
            # ë¯¸ë””ì–´ íŒŒì¼ë§Œ ì‚­ì œ
            if age > max_age_hours and fp.lower().endswith((".mp3", ".mp4", ".webm", ".m4a")):
                try:
                    os.remove(fp)
                    deleted_files += 1
                    print(f"[Cleanup] ì˜¤ë˜ëœ íŒŒì¼ ì‚­ì œ: {f}")
                except Exception as e:
                    print(f"[Cleanup] íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ ({f}): {e}")

    if deleted_files > 0:
        print(f"[Cleanup] {deleted_files}ê°œì˜ ì˜¤ë˜ëœ ë¯¸ë””ì–´ íŒŒì¼ì´ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("[Cleanup] ì‚­ì œí•  ì˜¤ë˜ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

def start_cleanup_scheduler(path="public/downloads", max_age_hours=24, interval_minutes=60):
    """
    FastAPI ì„œë²„ ì‹¤í–‰ ì‹œ ë°±ê·¸ë¼ìš´ë“œë¡œ ìë™ ì‹¤í–‰ë˜ëŠ” ì£¼ê¸°ì  ì •ë¦¬ ë£¨í”„.
    """
    def loop():
        print(f"[Cleanup Scheduler] ë°±ê·¸ë¼ìš´ë“œ íŒŒì¼ ì •ë¦¬ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ë¨. (ì£¼ê¸°: {interval_minutes}ë¶„ë§ˆë‹¤ ê²€ì‚¬)")
        while True:
            cleanup_downloads(path, max_age_hours)
            time.sleep(interval_minutes * 60)

    threading.Thread(target=loop, daemon=True).start()

# --- 5. ì„œë²„ ì‹¤í–‰ ---
if __name__ == "__main__":
    # ì„œë²„ ì‹¤í–‰ ì „ ì •ë¦¬ ë£¨í”„ ì‹œì‘
    start_cleanup_scheduler(path="public/downloads", max_age_hours=24, interval_minutes=60)
    uvicorn.run(app, host="0.0.0.0", port=8001)